{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d683a56-4be9-44e7-87c0-a6f20c55cd0a",
   "metadata": {},
   "source": [
    "# Part 2 - Other features analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffee260-60e7-43e7-ba59-f17c1759fcc2",
   "metadata": {},
   "source": [
    "The aim of our project is not clearly defined yet. We are hesitating between several topics:\n",
    "- predict the winner of the 1O0m sprint (or to define)\n",
    "- predict the winner of the marathon\n",
    "- have a look on the influence of being in your home country for french athletes at several event in the olympic games; such as surf, climbing, marathon, decathlon. The results of these events might be significantly impacted by the acclamation of the crowd, or the setup of the event can greatly facilitate a french athlete that is use to the meteorological condition...   \n",
    "\n",
    "In order to do them, our project will be divided in 3 parts:\n",
    "- a sentiment analysis using sports articles\n",
    "- a basic neural network machine learning algorithm on past performances/categorical features\n",
    "- a combination of the 2 above\n",
    "\n",
    "In this part we are doing the part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc702f2-96d6-45b8-9266-30964b198bb4",
   "metadata": {},
   "source": [
    "## Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d656ca2b-c037-48ac-bf97-39dbd4373727",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Web scrapping with *beautifulsoup4* from \n",
    "- the website https://worldathletics.org/world-rankings/5000m/men?regionType=world&page=1&rankDate=2024-06-04&limitByCountry=0\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce261233-562d-44c0-a188-4cfdc66bf199",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### *100m sprint*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43699c80-7c2a-492c-8296-c1924ad1642e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.11/site-packages (4.12.2)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.11/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c31ab19b-1955-466b-9ee0-50cb68362f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to 100m_sprint_all_time_toplist.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the page to scrape\n",
    "url = \"https://worldathletics.org/records/all-time-toplists/sprints/100-metres/outdoor/men/senior\"\n",
    "\n",
    "# Send a request to fetch the page content\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Ensure the request was successful\n",
    "\n",
    "# Parse the page content\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find the table containing the data\n",
    "table = soup.find('table')\n",
    "\n",
    "# Extract table headers\n",
    "headers = [header.text.strip() for header in table.find_all('th')]\n",
    "\n",
    "# Extract table rows\n",
    "rows = []\n",
    "for row in table.find_all('tr')[1:]:  # Skip the header row\n",
    "    columns = row.find_all('td')\n",
    "    row_data = [col.text.strip() for col in columns]\n",
    "    rows.append(row_data)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "df.to_csv('100m_sprint_all_time_toplist.csv', index=False)\n",
    "\n",
    "print(\"Data has been saved to 100m_sprint_all_time_toplist.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3814591-e2d4-4f11-9730-6fac74f40463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Mark</th>\n",
       "      <th>WIND</th>\n",
       "      <th>Competitor</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Nat</th>\n",
       "      <th>Pos</th>\n",
       "      <th></th>\n",
       "      <th>Venue</th>\n",
       "      <th>Date</th>\n",
       "      <th>Results Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9.58</td>\n",
       "      <td>+0.9</td>\n",
       "      <td>Usain BOLT</td>\n",
       "      <td>21 AUG 1986</td>\n",
       "      <td>JAM</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>Olympiastadion, Berlin (GER)</td>\n",
       "      <td>16 AUG 2009</td>\n",
       "      <td>1356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9.69</td>\n",
       "      <td>+2.0</td>\n",
       "      <td>Tyson GAY</td>\n",
       "      <td>09 AUG 1982</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>Shanghai (CHN)</td>\n",
       "      <td>20 SEP 2009</td>\n",
       "      <td>1316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9.69</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>Yohan BLAKE</td>\n",
       "      <td>26 DEC 1989</td>\n",
       "      <td>JAM</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>Stade Olympique de la Pontaise, Lausanne (SUI)</td>\n",
       "      <td>23 AUG 2012</td>\n",
       "      <td>1316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9.72</td>\n",
       "      <td>+0.2</td>\n",
       "      <td>Asafa POWELL</td>\n",
       "      <td>23 NOV 1982</td>\n",
       "      <td>JAM</td>\n",
       "      <td>1f1</td>\n",
       "      <td></td>\n",
       "      <td>Stade Olympique de la Pontaise, Lausanne (SUI)</td>\n",
       "      <td>02 SEP 2008</td>\n",
       "      <td>1305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9.74</td>\n",
       "      <td>+0.9</td>\n",
       "      <td>Justin GATLIN</td>\n",
       "      <td>10 FEB 1982</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>Suhaim bin Hamad Stadium, Doha (QAT)</td>\n",
       "      <td>15 MAY 2015</td>\n",
       "      <td>1298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>9.94</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>Bernard WILLIAMS</td>\n",
       "      <td>19 JAN 1978</td>\n",
       "      <td>USA</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>Commonwealth Stadium, Edmonton (CAN)</td>\n",
       "      <td>05 AUG 2001</td>\n",
       "      <td>1228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>95</td>\n",
       "      <td>9.94</td>\n",
       "      <td>+1.7</td>\n",
       "      <td>Diondre BATSON</td>\n",
       "      <td>13 JUL 1992</td>\n",
       "      <td>USA</td>\n",
       "      <td>2h2</td>\n",
       "      <td></td>\n",
       "      <td>Hayward Field, Eugene, OR (USA)</td>\n",
       "      <td>25 JUN 2015</td>\n",
       "      <td>1227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>95</td>\n",
       "      <td>9.94</td>\n",
       "      <td>+1.4</td>\n",
       "      <td>Andrew FISHER</td>\n",
       "      <td>15 DEC 1991</td>\n",
       "      <td>JAM</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>Moratalaz, Madrid (ESP)</td>\n",
       "      <td>11 JUL 2015</td>\n",
       "      <td>1227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>95</td>\n",
       "      <td>9.94</td>\n",
       "      <td>+1.0</td>\n",
       "      <td>Ameer WEBB</td>\n",
       "      <td>19 MAR 1991</td>\n",
       "      <td>USA</td>\n",
       "      <td>2f1</td>\n",
       "      <td></td>\n",
       "      <td>Stadio Olimpico, Roma (ITA)</td>\n",
       "      <td>02 JUN 2016</td>\n",
       "      <td>1227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>95</td>\n",
       "      <td>9.94</td>\n",
       "      <td>+0.9</td>\n",
       "      <td>Wayde VAN NIEKERK</td>\n",
       "      <td>15 JUL 1992</td>\n",
       "      <td>RSA</td>\n",
       "      <td>1f3</td>\n",
       "      <td></td>\n",
       "      <td>Velenje (SLO)</td>\n",
       "      <td>20 JUN 2017</td>\n",
       "      <td>1227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank  Mark  WIND         Competitor          DOB  Nat  Pos     \\\n",
       "0     1  9.58  +0.9         Usain BOLT  21 AUG 1986  JAM    1      \n",
       "1     2  9.69  +2.0          Tyson GAY  09 AUG 1982  USA    1      \n",
       "2     2  9.69  -0.1        Yohan BLAKE  26 DEC 1989  JAM    1      \n",
       "3     4  9.72  +0.2       Asafa POWELL  23 NOV 1982  JAM  1f1      \n",
       "4     5  9.74  +0.9      Justin GATLIN  10 FEB 1982  USA    1      \n",
       "..  ...   ...   ...                ...          ...  ...  ... ..   \n",
       "95   95  9.94  -0.2   Bernard WILLIAMS  19 JAN 1978  USA    2      \n",
       "96   95  9.94  +1.7     Diondre BATSON  13 JUL 1992  USA  2h2      \n",
       "97   95  9.94  +1.4      Andrew FISHER  15 DEC 1991  JAM    2      \n",
       "98   95  9.94  +1.0         Ameer WEBB  19 MAR 1991  USA  2f1      \n",
       "99   95  9.94  +0.9  Wayde VAN NIEKERK  15 JUL 1992  RSA  1f3      \n",
       "\n",
       "                                             Venue         Date Results Score  \n",
       "0                     Olympiastadion, Berlin (GER)  16 AUG 2009          1356  \n",
       "1                                   Shanghai (CHN)  20 SEP 2009          1316  \n",
       "2   Stade Olympique de la Pontaise, Lausanne (SUI)  23 AUG 2012          1316  \n",
       "3   Stade Olympique de la Pontaise, Lausanne (SUI)  02 SEP 2008          1305  \n",
       "4             Suhaim bin Hamad Stadium, Doha (QAT)  15 MAY 2015          1298  \n",
       "..                                             ...          ...           ...  \n",
       "95            Commonwealth Stadium, Edmonton (CAN)  05 AUG 2001          1228  \n",
       "96                 Hayward Field, Eugene, OR (USA)  25 JUN 2015          1227  \n",
       "97                         Moratalaz, Madrid (ESP)  11 JUL 2015          1227  \n",
       "98                     Stadio Olimpico, Roma (ITA)  02 JUN 2016          1227  \n",
       "99                                   Velenje (SLO)  20 JUN 2017          1227  \n",
       "\n",
       "[100 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2b8865-8215-4b12-98af-6cffac985573",
   "metadata": {},
   "source": [
    "We now have created a dataframe and saved it in a csv file. This gives us informations about the 100 first athletes for the 100m sprint in the world.\n",
    "\n",
    "We have 11 columns:\n",
    "- ID\n",
    "- Rank\n",
    "- Mark\n",
    "- WIND\n",
    "- Competitor (the name and surname of the athlete)\n",
    "- DOB (the date of birth)\n",
    "- NAT (nationality)\n",
    "- Pos (I don't know yet)\n",
    "- Venue (The venue in which he made his best time)\n",
    "- Date (the date he made his best time)\n",
    "- Result score\n",
    "\n",
    "We ideally want to have more information about each individual athlete. To do that, another page of this website has access to their profile page. We need to get access to it doing once again webscrapping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd69b812-bd03-4cda-b7b2-ad2277aedc9c",
   "metadata": {},
   "source": [
    "#### *5000m*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9ed1dda-138c-4197-a6a5-e16b8bf7f08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to 5000m_all_time_toplist.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the page to scrape\n",
    "url = \"https://worldathletics.org/world-rankings/5000m/men?regionType=world&page=1&rankDate=2024-06-04&limitByCountry=0\"\n",
    "\n",
    "# Send a request to fetch the page content\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Ensure the request was successful\n",
    "\n",
    "# Parse the page content\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find the table containing the data\n",
    "table = soup.find('table')\n",
    "\n",
    "# Extract table headers\n",
    "headers = [header.text.strip() for header in table.find_all('th')]\n",
    "\n",
    "# Extract table rows\n",
    "rows = []\n",
    "for row in table.find_all('tr')[1:]:  # Skip the header row\n",
    "    columns = row.find_all('td')\n",
    "    row_data = [col.text.strip() for col in columns]\n",
    "    rows.append(row_data)\n",
    "\n",
    "# Create a DataFrame\n",
    "df5000 = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "df5000.to_csv('5000m_all_time_toplist.csv', index=False)\n",
    "\n",
    "print(\"Data has been saved to 5000m_all_time_toplist.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf640dc9-98b4-445e-bf3a-53d96916ed59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Place</th>\n",
       "      <th>Competitor</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Nat</th>\n",
       "      <th>Score</th>\n",
       "      <th>Event List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yomif KEJELCHA</td>\n",
       "      <td>01 AUG 1997</td>\n",
       "      <td>ETH</td>\n",
       "      <td>1457</td>\n",
       "      <td>5000m [3000m]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Hagos GEBRHIWET</td>\n",
       "      <td>11 MAY 1994</td>\n",
       "      <td>ETH</td>\n",
       "      <td>1441</td>\n",
       "      <td>5000m [5 km Road]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Berihu AREGAWI</td>\n",
       "      <td>28 FEB 2001</td>\n",
       "      <td>ETH</td>\n",
       "      <td>1421</td>\n",
       "      <td>5000m [3000m]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Telahun Haile BEKELE</td>\n",
       "      <td>13 MAY 1999</td>\n",
       "      <td>ETH</td>\n",
       "      <td>1409</td>\n",
       "      <td>5000m [3000m]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Jakob INGEBRIGTSEN</td>\n",
       "      <td>19 SEP 2000</td>\n",
       "      <td>NOR</td>\n",
       "      <td>1405</td>\n",
       "      <td>5000m [3000m]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Jacob KIPLIMO</td>\n",
       "      <td>14 NOV 2000</td>\n",
       "      <td>UGA</td>\n",
       "      <td>1403</td>\n",
       "      <td>5000m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Selemon BAREGA</td>\n",
       "      <td>20 JAN 2000</td>\n",
       "      <td>ETH</td>\n",
       "      <td>1396</td>\n",
       "      <td>5000m [3000m sh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Grant FISHER</td>\n",
       "      <td>22 APR 1997</td>\n",
       "      <td>USA</td>\n",
       "      <td>1364</td>\n",
       "      <td>5000m [3000m]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Luis GRIJALVA</td>\n",
       "      <td>10 APR 1999</td>\n",
       "      <td>GUA</td>\n",
       "      <td>1361</td>\n",
       "      <td>5000m [3000m]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Joshua CHEPTEGEI</td>\n",
       "      <td>12 SEP 1996</td>\n",
       "      <td>UGA</td>\n",
       "      <td>1350</td>\n",
       "      <td>5000m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Place            Competitor          DOB  Nat Score         Event List\n",
       "0     1        Yomif KEJELCHA  01 AUG 1997  ETH  1457      5000m [3000m]\n",
       "1     2       Hagos GEBRHIWET  11 MAY 1994  ETH  1441  5000m [5 km Road]\n",
       "2     3        Berihu AREGAWI  28 FEB 2001  ETH  1421      5000m [3000m]\n",
       "3     4  Telahun Haile BEKELE  13 MAY 1999  ETH  1409      5000m [3000m]\n",
       "4     5    Jakob INGEBRIGTSEN  19 SEP 2000  NOR  1405      5000m [3000m]\n",
       "5     6         Jacob KIPLIMO  14 NOV 2000  UGA  1403              5000m\n",
       "6     7        Selemon BAREGA  20 JAN 2000  ETH  1396   5000m [3000m sh]\n",
       "7     8          Grant FISHER  22 APR 1997  USA  1364      5000m [3000m]\n",
       "8     9         Luis GRIJALVA  10 APR 1999  GUA  1361      5000m [3000m]\n",
       "9    10      Joshua CHEPTEGEI  12 SEP 1996  UGA  1350              5000m"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5000.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79488180-a1ca-4c3d-b41d-17106989727e",
   "metadata": {},
   "source": [
    "Let's find more details of these first 10 athletes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5edc62fd-372f-4349-8aa7-2ac8a53f461c",
   "metadata": {},
   "source": [
    "# List of athletes\n",
    "athletes = [\n",
    "    \"Yomif KEJELCHA\",\n",
    "    \"Hagos GEBRHIWET\",\n",
    "    \"Berihu AREGAWI\",\n",
    "    \"Telahun Haile BEKELE\",\n",
    "    \"Jakob INGEBRIGTSEN\",\n",
    "    \"Jacob KIPLIMO\",\n",
    "    \"Selemon BAREGA\",\n",
    "    \"Grant FISHER\",\n",
    "    \"Luis GRIJALVA\",\n",
    "    \"Joshua CHEPTEGEI\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb94f5ad-e105-4a29-a9ac-151262fee0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data has been saved to 'athlete_profile.json'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "# URL of the page to scrape\n",
    "url = \"https://worldathletics.org/athletes/ethiopia/hagos-gebrhiwet\"\n",
    "\n",
    "# Fetch the HTML content of the page\n",
    "response = requests.get(url)\n",
    "html_content = response.text\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find the <script> tag with id=\"__NEXT_DATA__\" and type=\"application/json\"\n",
    "script_tag = soup.find('script', {'id': '__NEXT_DATA__', 'type': 'application/json'})\n",
    "\n",
    "# Extract the JSON content from the <script> tag\n",
    "json_content = script_tag.string\n",
    "\n",
    "# Parse the JSON content\n",
    "data = json.loads(json_content)\n",
    "\n",
    "# Save the JSON content to a file\n",
    "with open('athlete_profile.json', 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=4)\n",
    "\n",
    "print(\"JSON data has been saved to 'athlete_profile.json'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2411a2f-77da-46e8-a607-55a83a484c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON data from the file\n",
    "with open('athlete_profile.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Function to recursively search for 5000 meters results\n",
    "def search_5000m_results(node, results):\n",
    "    if isinstance(node, dict):\n",
    "        for key, value in node.items():\n",
    "            if isinstance(value, list) or isinstance(value, dict):\n",
    "                search_5000m_results(value, results)\n",
    "            elif key == 'discipline' and '5000 Metres' in value:\n",
    "                results.append(node)\n",
    "    elif isinstance(node, list):\n",
    "        for item in node:\n",
    "            if isinstance(item, list) or isinstance(item, dict):\n",
    "                search_5000m_results(item, results)\n",
    "\n",
    "# Extract 5000 meters results\n",
    "results_5000m = []\n",
    "search_5000m_results(data, results_5000m)\n",
    "\n",
    "# Print the extracted results\n",
    "print(json.dumps(results_5000m, indent=4))\n",
    "\n",
    "\n",
    "\n",
    "# Optionally, save the extracted results to a file\n",
    "with open('5000m_results.json', 'w') as json_file:\n",
    "    json.dump(results_5000m, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb4ebce0-9093-40e9-9498-d7d2a57e9ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to 5000m_results.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the page to scrape\n",
    "url = \"https://worldathletics.org/athletes/ethiopia/hagos-gebrhiwet-14477352\"\n",
    "\n",
    "# Fetch the HTML content of the page\n",
    "response = requests.get(url)\n",
    "html_content = response.text\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find the <script> tag with id=\"__NEXT_DATA__\" and type=\"application/json\"\n",
    "script_tag = soup.find('script', {'id': '__NEXT_DATA__', 'type': 'application/json'})\n",
    "\n",
    "# Extract the JSON content from the <script> tag\n",
    "json_content = script_tag.string\n",
    "\n",
    "# Parse the JSON content\n",
    "data = json.loads(json_content)\n",
    "\n",
    "# Function to recursively search for 5000 meters results\n",
    "def search_5000m_results(node, results):\n",
    "    if isinstance(node, dict):\n",
    "        for key, value in node.items():\n",
    "            if isinstance(value, list) or isinstance(value, dict):\n",
    "                search_5000m_results(value, results)\n",
    "            elif key == 'discipline' and '5000 Metres' in value:\n",
    "                results.append(node)\n",
    "    elif isinstance(node, list):\n",
    "        for item in node:\n",
    "            if isinstance(item, list) or isinstance(item, dict):\n",
    "                search_5000m_results(item, results)\n",
    "\n",
    "# Extract 5000 meters results\n",
    "results_5000m = []\n",
    "search_5000m_results(data, results_5000m)\n",
    "\n",
    "data_athlete_5000m = results_5000m  # Remove json.dumps\n",
    "\n",
    "# List to hold the extracted rows\n",
    "rows = []\n",
    "\n",
    "# Function to extract relevant data\n",
    "def extract_5000m_data(results):\n",
    "    for result in results:\n",
    "        # Check if this is a progression result with multiple results\n",
    "        if 'results' in result:\n",
    "            for progression in result['results']:\n",
    "                rows.append({\n",
    "                    'score': progression.get('resultScore', ''),\n",
    "                    'date': progression.get('date', ''),\n",
    "                    'venue': progression.get('venue', ''),\n",
    "                    'place': progression.get('place', '')  # Use 'listPosition' instead of 'place'\n",
    "                })\n",
    "        else:\n",
    "            rows.append({\n",
    "                'score': result.get('resultScore', ''),\n",
    "                'date': result.get('date', ''),\n",
    "                'venue': result.get('venue', ''),\n",
    "                'place': result.get('place', '')  # Use 'listPosition' instead of 'place'\n",
    "            })\n",
    "\n",
    "# Extract data\n",
    "extract_5000m_data(data_athlete_5000m)\n",
    "\n",
    "# Define CSV file name\n",
    "csv_file_name = '5000m_results.csv'\n",
    "\n",
    "# Write to CSV\n",
    "with open(csv_file_name, 'w', newline='') as csv_file:\n",
    "    fieldnames = ['score', 'date', 'venue', 'place']  # Add 'place' to fieldnames\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for row in rows:\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"Data successfully written to {csv_file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "090ea613-119a-4c7e-b72d-14a4a16d027c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 5000m results for Yomif KEJELCHA...\n",
      "Extracting 5000m results for Hagos GEBRHIWET...\n",
      "Extracting 5000m results for Berihu AREGAWI...\n",
      "Extracting 5000m results for Telahun Haile BEKELE...\n",
      "Extracting 5000m results for Jakob INGEBRIGTSEN...\n",
      "Extracting 5000m results for Jacob KIPLIMO...\n",
      "Extracting 5000m results for Selemon BAREGA...\n",
      "Extracting 5000m results for Grant FISHER...\n",
      "Extracting 5000m results for Luis GRIJALVA...\n",
      "Extracting 5000m results for Joshua CHEPTEGEI...\n",
      "Data successfully written to 5000m_results.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Function to extract 5000m results for a given athlete URL\n",
    "def extract_5000m_results(url):\n",
    "    # Fetch the HTML content of the page\n",
    "    response = requests.get(url)\n",
    "    html_content = response.text\n",
    "\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Find the <script> tag with id=\"__NEXT_DATA__\" and type=\"application/json\"\n",
    "    script_tag = soup.find('script', {'id': '__NEXT_DATA__', 'type': 'application/json'})\n",
    "\n",
    "    # Extract the JSON content from the <script> tag\n",
    "    json_content = script_tag.string\n",
    "\n",
    "    # Parse the JSON content\n",
    "    data = json.loads(json_content)\n",
    "\n",
    "    # Function to recursively search for 5000 meters results\n",
    "    def search_5000m_results(node, results):\n",
    "        if isinstance(node, dict):\n",
    "            for key, value in node.items():\n",
    "                if isinstance(value, list) or isinstance(value, dict):\n",
    "                    search_5000m_results(value, results)\n",
    "                elif key == 'discipline' and '5000 Metres' in value:\n",
    "                    results.append(node)\n",
    "        elif isinstance(node, list):\n",
    "            for item in node:\n",
    "                if isinstance(item, list) or isinstance(item, dict):\n",
    "                    search_5000m_results(item, results)\n",
    "\n",
    "    # Extract 5000 meters results\n",
    "    results_5000m = []\n",
    "    search_5000m_results(data, results_5000m)\n",
    "\n",
    "    return results_5000m\n",
    "\n",
    "# List of athletes and their corresponding URLs\n",
    "athletes = {\n",
    "    \"Yomif KEJELCHA\": \"https://worldathletics.org/athletes/ethiopia/yomif-kejelcha-14594967\",\n",
    "    \"Hagos GEBRHIWET\": \"https://worldathletics.org/athletes/ethiopia/hagos-gebrhiwet-14477352\",\n",
    "    \"Berihu AREGAWI\": \"https://worldathletics.org/athletes/ethiopia/berihu-aregawi-14848753\",\n",
    "    \"Telahun Haile BEKELE\": \"https://worldathletics.org/athletes/ethiopia/telahun-haile-bekele-14797485\",\n",
    "    \"Jakob INGEBRIGTSEN\": \"https://worldathletics.org/athletes/norway/jakob-ingebrigtsen-14653717\",\n",
    "    \"Jacob KIPLIMO\": \"https://worldathletics.org/athletes/uganda/jacob-kiplimo-14735365\",\n",
    "    \"Selemon BAREGA\": \"https://worldathletics.org/athletes/ethiopia/selemon-barega-14751317\",\n",
    "    \"Grant FISHER\": \"https://worldathletics.org/athletes/united-states/grant-fisher-14591210\",\n",
    "    \"Luis GRIJALVA\": \"https://worldathletics.org/athletes/guatemala/luis-grijalva-14749285\",\n",
    "    \"Joshua CHEPTEGEI\": \"https://worldathletics.org/athletes/uganda/joshua-cheptegei-14645612\"\n",
    "}\n",
    "\n",
    "# List to hold all extracted rows\n",
    "all_rows = []\n",
    "\n",
    "# Loop through each athlete and extract their 5000m results\n",
    "for athlete, athlete_url in athletes.items():\n",
    "    print(f\"Extracting 5000m results for {athlete}...\")\n",
    "    athlete_results = extract_5000m_results(athlete_url)\n",
    "\n",
    "    # List to hold the extracted rows for this athlete\n",
    "    rows = []\n",
    "\n",
    "    # Function to extract relevant data\n",
    "    def extract_5000m_data(results):\n",
    "        for result in results:\n",
    "            # Check if this is a progression result with multiple results\n",
    "            if 'results' in result:\n",
    "                for progression in result['results']:\n",
    "                    rows.append({\n",
    "                        'Athlete': athlete,\n",
    "                        'Score': progression.get('resultScore', ''),\n",
    "                        'Date': progression.get('date', ''),\n",
    "                        'Venue': progression.get('venue', ''),\n",
    "                        'Place': progression.get('place', '')  # Use 'listPosition' instead of 'place'\n",
    "                    })\n",
    "            else:\n",
    "                rows.append({\n",
    "                    'Athlete': athlete,\n",
    "                    'Score': result.get('resultScore', ''),\n",
    "                    'Date': result.get('date', ''),\n",
    "                    'Venue': result.get('venue', ''),\n",
    "                    'Place': result.get('place', '')  # Use 'listPosition' instead of 'place'\n",
    "                })\n",
    "\n",
    "    # Extract data for this athlete\n",
    "    extract_5000m_data(athlete_results)\n",
    "\n",
    "    # Add rows for this athlete to the list of all rows\n",
    "    all_rows.extend(rows)\n",
    "\n",
    "# Define CSV file name\n",
    "csv_file_name = '5000m_results.csv'\n",
    "\n",
    "# Write all rows to CSV\n",
    "with open(csv_file_name, 'w', newline='') as csv_file:\n",
    "    fieldnames = ['Athlete', 'Score', 'Date', 'Venue', 'Place']  # Add 'Athlete' field\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for row in all_rows:\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"Data successfully written to {csv_file_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70e57b6-efd2-45f4-af99-67c4e218e00a",
   "metadata": {},
   "source": [
    "#### Climbing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ebc068e-b958-4ad3-98d2-2824be355c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561cdf76-4c77-41b4-ad91-9f76fa5585c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee64858-89a9-435d-b8a8-37b979bbbe0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
